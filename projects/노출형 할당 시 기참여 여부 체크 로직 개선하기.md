
## Background

- 광고할당 시 광고들이 해당 유저가 이미 참여한 광고인지 확인 후 해당 광고 리워드에 0으로 할당하거나 필터링하고 있습니다.
    
- 기참여 광고인지 확인하는 방법은 point table에서 적립내역으로 받아와서 기존 광고는 필터링합니다 .
    
- 헌데 기존 로직의 문제점으로 인해 유저가 interval 기간 내 재할당 및 적립을 받는 케이스가 발생하였습니다.
    

## Problem

- [이미 참여한건지 bs point에서 point item들을 조회](https://github.com/Buzzvil/buzzscreen-api/blob/master/internal/services/usecases/reward/repo/dynamo.go#L9-L20)하면서 받아오게 되는데 이 수치가 limit 이 100으로 걸려있음.
    

SearchLimit과 Limit이 걸려있는데 SearchLimit 이 100으로 하드코딩 고정값임.

- 특정 기간 내 할당 및 적립이 되어선 안되는 기간이 존재하는데 해당 기간내 100번 넘게 이미 참여한 경우, 이 기간내 재할당이 될 수 있는 구조임.
    
- limit을 걸고 조회하는 방식은 limit을 높일 수록 overhead가 발생하고 limit 수치 이상으로 유저가 참여하지 않는다는 보장을 받을 수 없는 상황이다.
    

## How to Solve

- 현재 상수값으로 limit을 걸고 dynamodb point item들을 받아와 loop을 돌면서 하나씩 체크하는 것이 아닌 방식으로 구조를 개선한다.
    
- Redis 를 사용하여 user:{device_id}:ad:{lineitem_id} (key) : {created_at} (value) 으로 insert 후 MGETcommand를 이용하여 기 참여여부를 판단한다.
    
- 기존 Dynamodb bs_point 에 source connector 로 카프카에 데이터를 쌓은 후 sink connector를 사용하여 Redis 에 TTL을 걸고 insert 한다.
    

## Points Requiring Comment

고민되는 점: Redis 키에 TTL을 걸기 위해선 clieck redirect url을 생성 시 ttl을 붙여주고, redirect 되었을 때 해당 ttl 값을 받아와서 bs_point item insert 시 추가 field(ttl)를 넣어줘야할 것 같습니다. 그래야 source connector, sink connector로 ttl을 걸고 insert가 가능할 것으로 보입니다. 그게 아니면 ttl 기간을 interval을 걸수 있는 최대치로 ttl을 걸어서 사용하는 방법이 있습니다. 이 둘중에 어떤 방법을 택할지, 다른 방법이 없을지 고민되었습니다. 우선 작업방향을 전자로 플래닝하였습니다.

ttl을 max치로 설정하면 redis memory를 추가적으로 더 사용하는 대신 ddb 저장 용량을 줄일 수 있고 하단 1, 2번 step 작업이 필요가 없습니다.

## Steps

1. clickredirect 시 재참여 기간인 interval을 ttl로 함께 parameter를 생성
    
2. clickredirect get 요청을 받으면 bs_point에 ttl field를 함께 저장
    
3. bs_point table 에 source connector 를 붙일 topic 생성
    
4. source connector 생성
    
5. 할당용 redis 연결
    
6. sink connector 생성 및 redis 에 키 적재 (user:{device_id}:ad:{lineitem_id} : {created_at} )
    
7. BS_API 기적립 체크 로직에서 Redis에서 MGET command로 created_at 을 받아와서 할당 가능한 interval 기간이 지났는지 확인하도록 함
    

## Deployment

device id를 //100 연산으로 퍼센트 단위로 일정부분씩 트래픽을 올리면서 로직 적용

## Due Date

1월 말에 라이브 예정되어 있음.

개인적인 의견으로는 우선 limit을 120, 150 수준으로 임시로 올려주고 대응이 가능한 상황으로 보임. (cs 들어오는 건들 tansaction_id 간에 차이를 보면 100초반에 형성되어 있음)

---

## **Considered**

- Redis가 아닌 dynamodb table을 별도 사용한다면, 사용 시 hash key( ad_id ,device_id 이용해서) 값을 adId_deviceID 로 설정하면 핫파티션키로부터 안전한건지 확인
    
- 해당 키를 언제 어떻게 insert 할지 고민방안
    
    - 1. 적립요청 kafka topic에 sink connector를 붙여서 키를 insert 한다.
        
        - 비동기 요청만 처리하고 있음으로 동기 로직은 별도 처리가 필요함. 현재는 bs_point에 쌓이는 것들은 동기로 적립되는 것이 없어서 괜찮지만 bs_point로 동기적립 케이스가 추후 생길경우 여기도 추가 작업을 해줘야하는 번거로움이 발생함.
            
    - 2. 적립완료 kafka topic에 sink connector를 붙여서 키를 insert 한다.
        
        - 적립 완료는 매체사로부터 적립 성공응답을 받아야 생성됩니다. 이 경우 매체사의 장애 혹은 문제로 인한 dependency가 발생합니다. 매체사에서 응답 지연이나 장애가 발생하는 동안 해당 지면에서 광고가 다시 재할당되는 문제가 우려됩니다.
            
    - 3. bs_point table에 insert될 때, 해당 키도 insert 한다.
        
        - BS 에서 해당 키를 insert하면 BS-API 에서 select하기에 각기 다른 서버에서 db를 공유하는 문제가 발생함. 두 서버가 추후 통합될 예정이라해도 bs 적립로직을 pointsvc 하나로 다 통합하고 싶은 방향을 고려하고 있는데 두개의 서버가 같은 db를 참조하게 됨.  
            이를 개선하기 위해서 insert 할 때 bs_point table에 source connector를 붙이고 카프카에 넣어서 sink connector로 조회할 db에 넣어주면 각기 다른 서버에서 같은 DB를 사용하는 문제를 해결할 순 있다.
            
    - 4. redis를 사용할 경우 bs_point와 각기 다른 두 db 혹은 dynamodb를 사용하면 별도 table에 insert가 되어야하는데 하나의 트랜잭션으로 보장이 필요한가?
        
        - 하나의 트랜잭션으로 묶어서 (적립용 bs_point insert + 광고 필터용 insert) 하나의 트랜잭션으로 관리하는게 오히려 적립 가용성을 떨어트리는 것 같음
            
        - 적립 bs_point item 생성 후 광고필터용 키를 insert시 현재 운영하는 방식과 달리 insert로직이 하나 더 추가되는데 여기서 실패하는 케이스가 발생할 수 있음. 이 경우 광고가 재할당되지만 적립 validation 로직이 돌면서 interval 내 재적립은 안되도록 되어있음. 광고를 봤음에도 리워드는 지급이 안되는 부분이라 CS가 강하게 들어오는 케이스가 발생함. 이 케이스를 개선할 방법은 없는 것인지? 이 측면에서 생각해보면, Redis보다 Dynamodb가 좀 더 고가용성 서비스인게 아닌가라는 관점에서 Dynamo에 한 표를 던져줄만함. 필터링 조회에서 fail이 발생하면 강성 CS가 발생하는데 버즈빌 근무하면서 Redis가 fail이 발생하는 케이스를 몇번 봤지만 Dynamo에서는 hot partition key 가능성만 없다면 fail 이 발생한 기억은 없음. dynamodb가 fulled managed라 편한 점도 있음.
            
        - application에서 각 db에 insert io를 한번씩 보내는 것 보다 bs_point 에 source connector를 붙이고 sink connector를 이용해서 insert를 하면 application에서 io를 한번 더 발생시킬 필요가 없는 장점이 있다. application에서 직접 insert하는 것에 비해 실패 건도 적을 것 같다
            
- Redis vs Dynamodb 비용 계산해보기
    
    - Redis: ttl 기간에 따라 메모리 사용량이 달라질 것이라 현재 예상이 어려움. ttl(interval 기간)이 보통 어떻게 잡혀있는지 잘 모르겠음.
        
    - Dynamodb: WCU - bs point 와 동일 / RCU - [BatchGetItem](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html) 하면서 어느정도 발생할지는 확인 필요
        

[https://aws.amazon.com/elasticache/pricing/](https://aws.amazon.com/elasticache/pricing/)

[https://aws.amazon.com/dynamodb/pricing/provisioned/](https://aws.amazon.com/dynamodb/pricing/provisioned/)

---

Redis를 선택한 이유:

저장용량이 지속적으로 꾸준히 증가할 케이스로 보이진 않으며 각 item(key) 별 데이터가 정형화되어 있음.

cluster mode까지 사용할 케이스가 아니기에 디테일을 계산하진 않았지만 secondary instance 만으로 더 저렴할 것을 예상

할당용 redis로 다른 use case가 생길 시 함께 공유하여 할당용 레디스로도 사용가능해보임.